{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO86Zk1tgiAf"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTHmiEMa63zf"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RRYSu48huSUW"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain huggingface_hub openai google-search-results tiktoken wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-KFB7J_u_3L",
        "outputId": "756b5088-e33c-4f78-b513-8ca387a13ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.347\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, anyio, async-timeout, dataclasses-json, jsonpatch, langchain-core, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.27.8 google-generativeai transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODLm6RHPkdq0",
        "outputId": "959ec146-35c2-49ff-bd7e-9852b3f0a44d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.27.8 in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (3.9.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.3.3 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.3.3)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.3.3->google-generativeai) (1.22.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (4.0.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.61.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.59.3)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQoDRN_WAa9K",
        "outputId": "d6d4ce1f-2d42-4afb-d813-15116b8d2c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.10/dist-packages (0.1.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.31.0)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.31.0.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchainhub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVIVVq9zqIRf",
        "outputId": "3de7d808-65c9-4d38-8506-6d661bdeaaa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (3.1.40)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython) (4.0.11)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gitpython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-VUtIHrzSyd"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uke0O_gtK1L9"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "import openai\n",
        "import os\n",
        "import git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wbtk_7Omea_"
      },
      "source": [
        "## Home"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Z0eEfYlTmf47"
      },
      "outputs": [],
      "source": [
        "class GitHome():\n",
        "\n",
        "    def __init__(self,\n",
        "                 work_dir,\n",
        "                 branch_name,\n",
        "                 repo_name,\n",
        "                 repo_home,\n",
        "                 user_name,\n",
        "                 user_token):\n",
        "        ### Save\n",
        "        os.environ[\"WORK_DIR\"] = work_dir\n",
        "        os.environ[\"BRANCH_NAME\"] = branch_name\n",
        "        os.environ[\"REPO_NAME\"] = repo_name\n",
        "        os.environ[\"GIT_HOME\"] = repo_home\n",
        "        os.environ[\"USER_NAME\"] = user_name\n",
        "        os.environ[\"USER_TOKEN\"] = user_token # Github Personal Access Token\n",
        "        ### Compose\n",
        "        os.environ[\"GIT_REPO\"] = os.environ[\"GIT_HOME\"] + os.environ[\"REPO_NAME\"]\n",
        "        os.environ[\"REPO_DIR\"] = os.environ[\"WORK_DIR\"] + \"/\" + os.environ[\"REPO_NAME\"]\n",
        "        os.environ[\"CLONE_FROM\"] = \"https://\" + os.environ[\"USER_NAME\"] + \":\" + os.environ[\"USER_TOKEN\"] + \"@github.com/\" + os.environ[\"USER_NAME\"] + \"/\" + os.environ[\"REPO_NAME\"] + \".git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjWhJUS8mvIR",
        "outputId": "2157ba26-bdb3-48aa-f946-6ad69f68e35e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.GitHome at 0x7ac9c8c3eef0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "GitHome(work_dir=\"/content/drive/MyDrive/StanfordLLM/thought-distillation\",\n",
        "        repo_name=\"thought-distillation\",\n",
        "        repo_home=\"https://github.com/pablo-tech/\",\n",
        "        branch_name=\"main\",\n",
        "        user_name=\"pablo-tech\",\n",
        "        user_token=\"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\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkFAElwHo5eM"
      },
      "source": [
        "## Git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Md0SURnQpXok",
        "outputId": "b386cc83-e82b-4fce-ece1-6f3424304c2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/StanfordLLM/thought-distillation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "os.environ[\"WORK_DIR\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xEptUKefo3k7"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  os.chdir(os.environ[\"WORK_DIR\"])\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!rm -rf $REPO_DIR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4tJJAvsqA5h",
        "outputId": "9f56c431-8533-4328-b2e2-4e04dac2c20e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<git.repo.base.Repo '/content/drive/MyDrive/StanfordLLM/thought-distillation/thought-distillation/.git'>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "git.Repo.clone_from(os.environ[\"CLONE_FROM\"], os.environ[\"REPO_DIR\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qSx-OETYqh3i"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.environ[\"REPO_DIR\"] + \"/source/main/py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "5T819TWbhGFb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_aFo9xECbyfx"
      },
      "outputs": [],
      "source": [
        "from model_base import AzureBase\n",
        "from tool_wikipedia import EncyclopediaToolFactory\n",
        "from model_bot import ChatBot\n",
        "from tool_search import SearchToolFactory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcNeCe90XH8p"
      },
      "source": [
        "# LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZsirev8otPS",
        "outputId": "92ac761a-80d2-4247-90bc-f3409559eb85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! engine is not default parameter.\n",
            "                engine was transferred to model_kwargs.\n",
            "                Please confirm that engine is what you intended.\n",
            "  warnings.warn(\n",
            "WARNING:langchain.chat_models.openai:WARNING! engine is not default parameter.\n",
            "                    engine was transferred to model_kwargs.\n",
            "                    Please confirm that engine is what you intended.\n"
          ]
        }
      ],
      "source": [
        "open_ai = AzureBase()\n",
        "\n",
        "inference_llm_35 = open_ai.inference_llm_35()\n",
        "chat_llm_40 = open_ai.chat_llm_40()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6KbZekHqtra",
        "outputId": "0cb3d19f-1bf6-4d65-844d-cc5fe541074d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('\\n\\nHi Bob! How are you?',\n",
              " AIMessage(content='Hello Bob! How can I assist you today?'))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "inference_llm_35.invoke(\"hi, i am bob\"), chat_llm_40.invoke(\"hi, i am bob\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWjV7nqiqKb3"
      },
      "source": [
        "# Chat bot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot = ChatBot(agent_llm=chat_llm_40,\n",
        "              agent_tools=EncyclopediaToolFactory(chat_llm_40).get_tools(),\n",
        "              is_verbose=True)\n",
        "\n",
        "queries = [\"hi, my name is Bob\",\n",
        "           \"what is my name?\"]\n",
        "\n",
        "for q in queries:\n",
        "    response = bot.invoke(q)\n",
        "    print(\"user: \" + str(q))\n",
        "    print(\"agent: \" + str(response.get_answer()))\n",
        "    print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBuFCtXzvSkz",
        "outputId": "56d02b7e-75bf-4d44-9cee-058e6efada1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EXECUTOR_RUN_DETAIL=>\n",
            " - RUN_ANSWER: Hello Bob, how can I assist you today?\n",
            " - RUN_NORMAL: True\n",
            " - RUN_JOURNEY: \n",
            "Thought: The user has introduced themselves as Bob. This doesn't seem to be a question, but a greeting or introduction. I should respond in a polite and welcoming manner.\n",
            "Action: Finish[Hello Bob, how can I assist you today?]\n",
            "Observation: Hello Bob, how can I assist you today?\n",
            " - RUN_MEASURE => \n",
            "\t iteration_count: 1\n",
            "\t hallucination_count: 0\n",
            "\t min_input_len: 3888\n",
            "\t max_input_len: 3888\n",
            "\t total_input_len: 3888\n",
            "\t min_output_len: 225\n",
            "\t max_output_len: 225\n",
            "\t total_output_len: 225\n",
            "\t min_model_time: 3.216\n",
            "\t max_model_time: 3.216\n",
            "\t total_model_time: 3.216\n",
            " - RUN_EXCEPTION =>\n",
            "\n",
            "\n",
            "user: hi, my name is Bob\n",
            "agent: Hello Bob, how can I assist you today?\n",
            "EXECUTOR_RUN_DETAIL=>\n",
            " - RUN_ANSWER: Hello Bob, how can I assist you today?\n",
            " - RUN_NORMAL: True\n",
            " - RUN_JOURNEY: \n",
            "Thought: The user has introduced themselves as Bob. This doesn't seem to be a question, but a greeting or introduction. I should respond in a polite and welcoming manner.\n",
            "Action: Finish[Hello Bob, how can I assist you today?]\n",
            "Observation: Hello Bob, how can I assist you today?\n",
            " - RUN_MEASURE => \n",
            "\t iteration_count: 1\n",
            "\t hallucination_count: 0\n",
            "\t min_input_len: 3888\n",
            "\t max_input_len: 3888\n",
            "\t total_input_len: 3888\n",
            "\t min_output_len: 225\n",
            "\t max_output_len: 225\n",
            "\t total_output_len: 225\n",
            "\t min_model_time: 3.216\n",
            "\t max_model_time: 3.216\n",
            "\t total_model_time: 3.216\n",
            " - RUN_EXCEPTION =>\n",
            "\n",
            "\n",
            "EXECUTOR_RUN_DETAIL=>\n",
            " - RUN_ANSWER: Your name is Bob.\n",
            " - RUN_NORMAL: True\n",
            " - RUN_JOURNEY: \n",
            "Thought: The user previously stated that his name is Bob.\n",
            "Action: Finish[Your name is Bob.]\n",
            "Observation: Your name is Bob.\n",
            " - RUN_MEASURE => \n",
            "\t iteration_count: 2\n",
            "\t hallucination_count: 0\n",
            "\t min_input_len: 3888\n",
            "\t max_input_len: 4054\n",
            "\t total_input_len: 7942\n",
            "\t min_output_len: 91\n",
            "\t max_output_len: 225\n",
            "\t total_output_len: 316\n",
            "\t min_model_time: 1.087\n",
            "\t max_model_time: 3.216\n",
            "\t total_model_time: 4.303\n",
            " - RUN_EXCEPTION =>\n",
            "\n",
            "\n",
            "user: what is my name?\n",
            "agent: Your name is Bob.\n",
            "EXECUTOR_RUN_DETAIL=>\n",
            " - RUN_ANSWER: Your name is Bob.\n",
            " - RUN_NORMAL: True\n",
            " - RUN_JOURNEY: \n",
            "Thought: The user previously stated that his name is Bob.\n",
            "Action: Finish[Your name is Bob.]\n",
            "Observation: Your name is Bob.\n",
            " - RUN_MEASURE => \n",
            "\t iteration_count: 2\n",
            "\t hallucination_count: 0\n",
            "\t min_input_len: 3888\n",
            "\t max_input_len: 4054\n",
            "\t total_input_len: 7942\n",
            "\t min_output_len: 91\n",
            "\t max_output_len: 225\n",
            "\t total_output_len: 316\n",
            "\t min_model_time: 1.087\n",
            "\t max_model_time: 3.216\n",
            "\t total_model_time: 4.303\n",
            " - RUN_EXCEPTION =>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation (Hotpot)"
      ],
      "metadata": {
        "id": "FAnsbEiqgbdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wikipedia"
      ],
      "metadata": {
        "id": "euSqNhy5pmxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bot = ChatBot(agent_llm=chat_llm_40,\n",
        "              agent_tools=EncyclopediaToolFactory(chat_llm_40).get_tools(),\n",
        "              is_verbose=True)\n",
        "\n",
        "bot.invoke(\"Where was the XXXI Olympic held\").get_answer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIMbYF4egjST",
        "outputId": "fb88fc78-6f70-429f-a5f2-e5ba09dbd7ad"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMEOUT...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot = ChatBot(agent_llm=chat_llm_40,\n",
        "              agent_tools=EncyclopediaToolFactory(chat_llm_40).get_tools(),\n",
        "              is_verbose=True)\n",
        "\n",
        "bot.invoke(\"What was the name of the Olympic event held in Rio\").get_answer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6btvkOEBgzIp",
        "outputId": "4295c579-ca47-4261-d362-521271e7e535"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMEOUT...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot = ChatBot(agent_llm=chat_llm_40,\n",
        "              agent_tools=EncyclopediaToolFactory(chat_llm_40).get_tools(),\n",
        "              is_verbose=True)\n",
        "\n",
        "bot.invoke(\"When was the flag bearer of Rio Olympics born\").get_answer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77tBJXi-g9Ym",
        "outputId": "c0214b0a-999e-41e5-e037-29899c7a9de8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMEOUT...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot = ChatBot(agent_llm=chat_llm_40,\n",
        "              agent_tools=EncyclopediaToolFactory(chat_llm_40).get_tools(),\n",
        "              is_verbose=True)\n",
        "\n",
        "bot.invoke(\"When was the flag bearer of Rio Olympics born\").get_answer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcgH-uq5i1TC",
        "outputId": "0cbce6ea-11cb-42d6-cad6-821fae8f3774"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMEOUT...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search"
      ],
      "metadata": {
        "id": "LaNzndNdpx_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bot = ChatBot(agent_llm=chat_llm_40,\n",
        "              agent_tools=SearchToolFactory(chat_llm_40).get_tools(),\n",
        "              is_verbose=True)\n",
        "\n",
        "bot.invoke(\"Which male bearer participated in Men's 100kg event in the Rio Olympic game\").get_answer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqot22zjhQcQ",
        "outputId": "908ae6a4-f330-46a2-af9a-61213369d02f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMEOUT...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot = ChatBot(agent_llm=chat_llm_40,\n",
        "              agent_tools=SearchToolFactory(chat_llm_40).get_tools(),\n",
        "              is_verbose=True)\n",
        "\n",
        "bot.invoke(\"For the 2012 and 2016 Olympic Event, when was the younger flag bearer born\").get_answer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcIwzljMhpU0",
        "outputId": "88f9cb7b-6964-44b3-d5ec-40af77842f8e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMEOUT...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSTMQX47lFcz"
      },
      "source": [
        "# References\n",
        "- https://youtu.be/Eug2clsLtFs?si=vuumOZNA6GXjaIay\n",
        "- https://python.langchain.com/docs/modules/agents/agent_types/react"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "lO86Zk1tgiAf",
        "F-VUtIHrzSyd",
        "UcNeCe90XH8p",
        "kWjV7nqiqKb3"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}